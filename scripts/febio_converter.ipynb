{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import meshio as mio\n",
    "import json\n",
    "import os\n",
    "\n",
    "import meshplot as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmsh_dim_tags(points, cells, tags):\n",
    "    dim_tags = np.tile([3, 1], [points.shape[0], 1])\n",
    "    for i, cell in enumerate(cells):\n",
    "        for vi in cell:\n",
    "            dim_tags[vi, 1] = tags[i]\n",
    "    return dim_tags\n",
    "\n",
    "\n",
    "def gmsh_cell_tags(tags):\n",
    "    cell_tags = [[tags[0]]]\n",
    "    for tag in tags[1:]:\n",
    "        if tag == cell_tags[-1][-1]:\n",
    "            cell_tags[-1].append(tag)\n",
    "        else:\n",
    "            cell_tags.append([tag])\n",
    "    return cell_tags\n",
    "\n",
    "\n",
    "def split_cells_by_tags(tags, cells):\n",
    "    assert(len(tags) == len(cells))\n",
    "    split_cells = [[cells[0]]]\n",
    "    for i, tag in enumerate(tags[1:]):\n",
    "        if tag == tags[i]:\n",
    "            split_cells[-1].append(cells[i + 1])\n",
    "        else:\n",
    "            split_cells.append([cells[i + 1]])\n",
    "    return split_cells\n",
    "\n",
    "\n",
    "def save_msh(file, points, tets, tags):\n",
    "    dim_tags = gmsh_dim_tags(points, tets, tags)\n",
    "    cell_tags = gmsh_cell_tags(tags)\n",
    "\n",
    "    tmp = [(\"tetra\", np.array(cells)) for cells in split_cells_by_tags(tags, tets)]\n",
    "    # print([(\"tetra\", T)])\n",
    "    # [(\"tetra\", T)]\n",
    "\n",
    "\n",
    "    mesh = mio.Mesh(\n",
    "        points,\n",
    "        tmp,\n",
    "        point_data={\"gmsh:dim_tags\": dim_tags},\n",
    "        cell_data={\"gmsh:physical\": cell_tags, \"gmsh:geometrical\": cell_tags}\n",
    "    )\n",
    "\n",
    "    mio.write(file, mesh, binary=True, file_format=\"gmsh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_control(control, args):\n",
    "    if control is None:\n",
    "        return\n",
    "        \n",
    "    tsn = control.find(\"time_steps\")\n",
    "    ssn = control.find(\"step_size\")\n",
    "    an = control.find(\"analysis\")\n",
    "\n",
    "    \n",
    "    if tsn is not None and ssn is not None and an is not None:\n",
    "        if an.attrib[\"type\"] == \"dynamic\":\n",
    "            time_steps = int(tsn.text)\n",
    "            step_size = float(ssn.text)\n",
    "\n",
    "            args[\"time\"] = {\n",
    "                \"tend\": step_size * time_steps,\n",
    "                \"time_steps\": time_steps\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_materials(febio):\n",
    "    materials = {}\n",
    "\n",
    "    material_parent = febio.find(\"Material\")\n",
    "    \n",
    "    for material_node in material_parent.iter(\"material\"):\n",
    "        material = material_node.attrib[\"type\"]\n",
    "        mid = int(material_node.attrib[\"id\"])+1\n",
    "        \n",
    "        E = float(material_node.find(\"E\").text)\n",
    "        nu = float(material_node.find(\"v\").text)\n",
    "                  \n",
    "        if material_node.find(\"density\") is None:\n",
    "            rho = 1\n",
    "        else:\n",
    "            rho = float(material_node.find(\"density\").text)\n",
    "\n",
    "        mat = \"\"\n",
    "        if material == \"neo-Hookean\":\n",
    "            mat = \"NeoHookean\"\n",
    "        elif material == \"isotropic elastic\":\n",
    "            mat = \"LinearElasticity\"\n",
    "        else:\n",
    "            print(\"Unsupported material {}, reverting to isotropic elastic\".format(material))\n",
    "            mat = \"LinearElasticity\"\n",
    "            \n",
    "\n",
    "        materials[mid] = {\"id\": mid, \"E\": E, \"nu\": nu, \"rho\": rho, \"type\": mat}\n",
    "        \n",
    "    return materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nodes(geometry):\n",
    "    vertices = []\n",
    "    for nodes in geometry.iter(\"Nodes\"):\n",
    "        for child in nodes.iter(\"node\"):\n",
    "            pos_str = child.text\n",
    "            vs = pos_str.split(\",\")\n",
    "            assert(len(vs) == 3);\n",
    "            \n",
    "            vertices.append([float(vs[0]), float(vs[1]), float(vs[2])])\n",
    "\n",
    "\n",
    "    V = np.array(vertices)\n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_elements(geometry, numV, materials):\n",
    "    els = []\n",
    "    nodes = []\n",
    "    mids = []\n",
    "    \n",
    "    order = 1\n",
    "    \n",
    "    is_hex = False\n",
    "    types = \"\"\n",
    "    \n",
    "    for elements in geometry.iter(\"Elements\"):\n",
    "        el_type = elements.attrib[\"type\"]\n",
    "        mid = int(elements.attrib[\"mat\"])+1\n",
    "\n",
    "        if el_type != \"tet4\" and el_type != \"tet10\" and el_type != \"tet20\" and el_type != \"hex8\":\n",
    "            print(\"Unsupported elemet type {}\".format(el_type))\n",
    "            continue\n",
    "\n",
    "\n",
    "        if len(types) == 0:\n",
    "            if el_type.startswith(\"tet\"):\n",
    "                types = \"tet\"\n",
    "            else:\n",
    "                types = \"hex\"\n",
    "        elif not el_type.startswith(types, 0):\n",
    "            print(\"Unsupported elemet type {} since the mesh contains also {}\".format(el_type, types))\n",
    "            continue\n",
    "\n",
    "        if el_type == \"tet4\":\n",
    "            order = max(1, order)\n",
    "        elif el_type == \"tet10\":\n",
    "            order = max(2, order)\n",
    "        elif el_type == \"tet20\":\n",
    "            order = max(3, order)\n",
    "        elif el_type == \"hex8\":\n",
    "            order = max(1, order)\n",
    "            is_hex = True\n",
    "                \n",
    "\n",
    "        for child in elements.iter(\"elem\"):\n",
    "                ids = child.text\n",
    "                tt = ids.split(\",\");\n",
    "                assert(len(tt) >= 4);\n",
    "                \n",
    "                node_size = 8 if is_hex else 4\n",
    "\n",
    "                els.append([])\n",
    "                \n",
    "                for n in range(node_size):\n",
    "                    els[-1].append(int(tt[n]) - 1)\n",
    "                    assert(els[-1][n] < numV)\n",
    "\n",
    "                nodes.append([])\n",
    "                mids.append(mid)\n",
    "                \n",
    "                for n in range(len(tt)):\n",
    "                    nodes[-1].append(int(tt[n]) - 1)\n",
    "\n",
    "                if el_type == \"tet10\":\n",
    "                    assert(len(nodes[-1]) == 10)\n",
    "                    nodes[-1][8], nodes[-1][9] = nodes[-1][9], nodes[-1][8]\n",
    "                elif el_type == \"tet20\":\n",
    "                    assert(len(nodes[-1]) == 20)\n",
    "                    nodes[-1][8], nodes[-1][9] = nodes[-1][9], nodes[-1][8]\n",
    "                    nodes[-1][10], nodes[-1][11] = nodes[-1][11], nodes[-1][10]\n",
    "                    nodes[-1][12], nodes[-1][15] = nodes[-1][15], nodes[-1][12]\n",
    "                    nodes[-1][13], nodes[-1][14] = nodes[-1][14], nodes[-1][13]\n",
    "                    nodes[-1][16], nodes[-1][19] = nodes[-1][19], nodes[-1][16]\n",
    "                    nodes[-1][17], nodes[-1][19] = nodes[-1][19], nodes[-1][17]\n",
    "\n",
    "\n",
    "    T = np.array(els)\n",
    "                \n",
    "    return T, np.array(mids), order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_node_sets(geometry):\n",
    "    nodes_set = {}\n",
    "    \n",
    "    for child in geometry.iter(\"NodeSet\"):\n",
    "        name = child.attrib[\"name\"]\n",
    "                \n",
    "        for nodeid in child.iter(\"node\"):\n",
    "            nid = int(nodeid.attrib[\"id\"])-1\n",
    "            nodes_set[nid] = name\n",
    "\n",
    "            \n",
    "    return nodes_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dirichlet(boundaries, nodes_set, dt):\n",
    "    allbc = {}\n",
    "    \n",
    "    names = [nodes_set[k] for k in nodes_set]\n",
    "    \n",
    "    result = np.zeros((len(nodes_set), 4))\n",
    "    result[:, 0] = np.array([k for k in node_set])\n",
    "    \n",
    "    for child in boundaries.iter(\"fix\"):\n",
    "        name = child.attrib[\"node_set\"]\n",
    "        \n",
    "        if not name in names:\n",
    "            print(\"Sideset {} not present, skipping\".format(name))\n",
    "            continue\n",
    "\n",
    "        bc = child.attrib[\"bc\"]\n",
    "        bcs = bc.split(\",\")\n",
    "\n",
    "        value = np.array([0.,0.,0.])\n",
    "\n",
    "        if not \"x\" in bcs:\n",
    "            value[0] = np.NAN\n",
    "        if not \"y\" in bcs:\n",
    "            value[1] = np.NAN\n",
    "        if not \"z\" in bcs:\n",
    "            value[2] = np.NAN\n",
    "\n",
    "        for i,k in enumerate(node_set):\n",
    "            if node_set[k] == name:\n",
    "                result[i, 1:] = value\n",
    "                                \n",
    "\n",
    "    for child in boundaries.iter(\"prescribe\"):\n",
    "        name = child.attrib[\"node_set\"]\n",
    "        if not name in names:\n",
    "            print(\"Sideset {} not present, skipping\".format(name))\n",
    "            continue\n",
    "\n",
    "        bc = child.attrib[\"bc\"]\n",
    "        bcs = bc.split(\",\")\n",
    "        val = float(child.find(\"scale\").text) * dt\n",
    "        value = np.array([val, val, val])\n",
    "        \n",
    "        if not \"x\" in bcs:\n",
    "            value[0] = np.NAN\n",
    "        if not \"y\" in bcs:\n",
    "            value[1] = np.NAN\n",
    "        if not \"z\" in bcs:\n",
    "            value[2] = np.NAN\n",
    "\n",
    "        for i,k in enumerate(node_set):\n",
    "            if node_set[k] == name:\n",
    "                result[i, 1:] = value\n",
    "\n",
    "\n",
    "#             for (const tinyxml2::XMLElement *child = boundaries->FirstChildElement(\"vector_bc\"); child != NULL; child = child->NextSiblingElement(\"vector_bc\"))\n",
    "#             {\n",
    "#                 const std::string name = std::string(child->Attribute(\"node_set\"));\n",
    "#                 if (names.find(name) == names.end())\n",
    "#                 {\n",
    "#                     logger().error(\"Sideset {} not present, skipping\", name);\n",
    "#                     continue;\n",
    "#                 }\n",
    "#                 const int id = names.at(name);\n",
    "#                 const std::string centers = resolve_path(std::string(child->Attribute(\"centers\")), root_file);\n",
    "#                 const std::string values = resolve_path(std::string(child->Attribute(\"values\")), root_file);\n",
    "#                 const std::string rbf = \"thin_plate\"; //TODO\n",
    "#                 const double eps = 1e-3;              //TODO\n",
    "#                 //TODO add is x,y,z\n",
    "\n",
    "#                 Eigen::MatrixXd centers_mat, values_mat;\n",
    "#                 read_matrix(centers, centers_mat);\n",
    "#                 read_matrix(values, values_mat);\n",
    "\n",
    "#                 RBFInterpolation interp(values_mat, centers_mat, rbf, eps);\n",
    "#                 logger().trace(\"adding vector Dirichlet id={} centers={} values={} rbf={} eps={}\", id, centers, values, rbf, eps);\n",
    "\n",
    "#                 gproblem.add_dirichlet_boundary(\n",
    "#                     id, [interp](double x, double y, double z, double t) {\n",
    "#                         Eigen::Matrix<double, 3, 1> v;\n",
    "#                         v[0] = x;\n",
    "#                         v[1] = y;\n",
    "#                         v[2] = z;\n",
    "#                         return interp.interpolate(v);\n",
    "#                     },\n",
    "#                     true, true, true, get_interpolation(gproblem.is_time_dependent()));\n",
    "#             }\n",
    "\n",
    "#             const bool is_time_dept = gproblem.is_time_dependent();\n",
    "#             for (const tinyxml2::XMLElement *child = boundaries->FirstChildElement(\"scaling\"); child != NULL; child = child->NextSiblingElement(\"scaling\"))\n",
    "#             {\n",
    "#                 const std::string centres = std::string(child->Attribute(\"center\"));\n",
    "#                 const std::string factors = std::string(child->Attribute(\"factor\"));\n",
    "#                 const std::string name = std::string(child->Attribute(\"node_set\"));\n",
    "#                 if (names.find(name) == names.end())\n",
    "#                 {\n",
    "#                     logger().error(\"Sideset {} not present, skipping\", name);\n",
    "#                     continue;\n",
    "#                 }\n",
    "#                 const int id = names.at(name);\n",
    "\n",
    "#                 const auto centrec = StringUtils::split(centres, \",\");\n",
    "#                 if (centrec.size() != 3)\n",
    "#                 {\n",
    "#                     logger().error(\"Skipping scaling, center is not 3d\");\n",
    "#                     continue;\n",
    "#                 }\n",
    "#                 const Eigen::Vector3d center(\n",
    "#                     atof(centrec[0].c_str()),\n",
    "#                     atof(centrec[1].c_str()),\n",
    "#                     atof(centrec[2].c_str()));\n",
    "\n",
    "#                 const double scaling = atof(factors.c_str());\n",
    "#                 logger().trace(\"adding scaling Dirichlet id={} center=({}) scaling={}\", id, center.transpose(), scaling);\n",
    "#                 gproblem.add_dirichlet_boundary(\n",
    "#                     id, [center, scaling, is_time_dept](double x, double y, double z, double t) {\n",
    "#                         Eigen::Matrix<double, 3, 1> v;\n",
    "#                         Eigen::Matrix<double, 3, 1> target;\n",
    "#                         v[0] = x;\n",
    "#                         v[1] = y;\n",
    "#                         v[2] = z;\n",
    "#                         target = v;\n",
    "\n",
    "#                         const double s = is_time_dept ? (scaling * t) : scaling;\n",
    "#                         target -= center;\n",
    "#                         target *= s;\n",
    "#                         target += center;\n",
    "#                         return (target - v).eval();\n",
    "#                     },\n",
    "#                     true, true, true);\n",
    "#             }\n",
    "#         }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_neumann(loads, names, dt):\n",
    "    result = []\n",
    "    \n",
    "    if loads is None:\n",
    "        return result\n",
    "    \n",
    "    for child in loads.iter(\"surface_load\"):\n",
    "        name = child.attrib[\"surface\"]\n",
    "        btype = child.attrib[\"type\"]\n",
    "        assert(name in names)\n",
    "        \n",
    "        if btype == \"traction\":\n",
    "            traction = child.find(\"traction\").text\n",
    "            scalev = np.array([1., 1., 1.])\n",
    "            \n",
    "            for scale in child.iter(\"scale\"):\n",
    "                scales = scale.text\n",
    "                scalev *= float(scales)\n",
    "\n",
    "\n",
    "            bcs = traction.split(\",\")\n",
    "            assert(len(bcs) == 3)\n",
    "\n",
    "            force = np.array([float(v) for v in bcs])\n",
    "            force *= scalev*dt\n",
    "            \n",
    "            \n",
    "            print(\"adding Neumann id={} force=({})\".format(names[name], force))\n",
    "\n",
    "            result.append({\n",
    "                \"type\": \"neumann\",\n",
    "                \"id\": names[name],\n",
    "                \"value\": force\n",
    "                #get_interpolation(gproblem.is_time_dependent())\n",
    "            })\n",
    "        \n",
    "        elif btype == \"pressure\":\n",
    "            pressures = child.find(\"pressure\").text\n",
    "            \n",
    "            # TODO added minus here\n",
    "            pressure = -float(pressures) * dt\n",
    "\n",
    "            print(\"adding Pressure id={} pressure={}\".format(names[name], pressure))\n",
    "                        \n",
    "            result.append({\n",
    "                \"type\": \"pressure\",\n",
    "                \"id\": names[name],\n",
    "                \"value\": pressure\n",
    "                #get_interpolation(gproblem.is_time_dependent())\n",
    "            })\n",
    "        else:\n",
    "            print(\"Unsupported surface load {}\".format(btype))\n",
    "\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_surface_selection(geometry):\n",
    "    n_id = 1\n",
    "    names = {}\n",
    "    \n",
    "    selections = []\n",
    "    \n",
    "    for child in geometry.iter(\"Surface\"):\n",
    "        name = child.attrib[\"name\"]\n",
    "        names[name] = n_id;\n",
    "        \n",
    "\n",
    "        # TODO  only tri3\n",
    "        for nodeid in child.iter(\"tri3\"):\n",
    "            ids = nodeid.text\n",
    "            tt = ids.split(\",\")\n",
    "            assert(len(tt) == 3)\n",
    "            \n",
    "            selections.append([n_id] + [int(v) - 1 for v in tt])\n",
    "\n",
    "        for nodeid in child.iter(\"quad4\"):\n",
    "            ids = nodeid.text\n",
    "            tt = ids.split(\",\")\n",
    "            assert(len(tt) == 4)\n",
    "\n",
    "            tmp.append([int(v) - 1 for v in tt])\n",
    "\n",
    "        n_id += 1\n",
    "            \n",
    "    return np.array(selections), names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder = \"\"\n",
    "dhat = 0.001\n",
    "output = \"sim.vtu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_json = {}\n",
    "output_json[\"output\"] = {\n",
    "    \"json\": \"sim.json\",\n",
    "    \"paraview\": {\n",
    "            \"file_name\": output,\n",
    "            \"surface\": True,\n",
    "            \"options\": {\n",
    "                \"material\": True,\n",
    "                \"body_ids\": True\n",
    "            },\n",
    "            \"vismesh_rel_area\": 10000000\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding Neumann id=1 force=([0. 0. 1.])\n"
     ]
    }
   ],
   "source": [
    "# tree = ET.parse(\"../data/test.feb\")\n",
    "tree = ET.parse(\"../data/lin-neo.feb\")\n",
    "\n",
    "root = tree.getroot()\n",
    "\n",
    "if root.attrib[\"version\"] != \"2.5\":\n",
    "    assert(False)\n",
    "    \n",
    "control = root.find(\"Control\")\n",
    "load_control(control, output_json)\n",
    "\n",
    "dt = 1\n",
    "\n",
    "if \"time\" in output_json:\n",
    "    dt = output_json[\"time\"][\"time_steps\"]\n",
    "\n",
    "materials = load_materials(root)\n",
    "\n",
    "    \n",
    "geometry = root.find(\"Geometry\");\n",
    "\n",
    "V = load_nodes(geometry)\n",
    "T, mids, order = load_elements(geometry, V.shape[0], {})\n",
    "\n",
    "node_set = load_node_sets(geometry)\n",
    "\n",
    "\n",
    "boundaries = root.find(\"Boundary\");\n",
    "dirichlet = load_dirichlet(boundaries, node_set, dt)\n",
    "\n",
    "surfs, names = load_surface_selection(geometry)\n",
    "loads = root.find(\"Loads\")\n",
    "neumann = load_neumann(loads, names, dt)\n",
    "\n",
    "\n",
    "has_collisions = geometry.find(\"SurfacePair\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####################################################\n",
    "################## Output ###########################\n",
    "#####################################################\n",
    "\n",
    "if has_collisions:\n",
    "    output_json[\"contact\"] = {\n",
    "        \"enabled\": True,\n",
    "        \"dhat\": dhat\n",
    "    }\n",
    "\n",
    "\n",
    "output_json[\"materials\"] = [materials[k] for k in materials] if len(materials) > 1 else list(materials.values())[0]\n",
    "output_json[\"boundary_conditions\"] = {}\n",
    "\n",
    "\n",
    "output_json[\"geometry\"] = {\n",
    "    \"mesh\": os.path.join(out_folder,\"mesh.msh\"),\n",
    "    \"surface_selection\": \"\" if surfs.size <= 0 else os.path.join(out_folder,\"surfaces.txt\")\n",
    "}\n",
    "\n",
    "if surfs.size > 0:\n",
    "    np.savetxt(os.path.join(out_folder,\"surfaces.txt\"), surfs, fmt='%d')\n",
    "\n",
    "save_msh(os.path.join(out_folder,\"mesh.msh\"), V, T, mids)\n",
    "\n",
    "for n in neumann:\n",
    "    output_json[\"boundary_conditions\"][\"neumann_boundary\"] = []\n",
    "    output_json[\"boundary_conditions\"][\"pressure_boundary\"] = []\n",
    "    if n[\"type\"] == \"neumann\":\n",
    "        output_json[\"boundary_conditions\"][\"neumann_boundary\"].append({\n",
    "            \"id\": n[\"id\"],\n",
    "            \"value\": list(n[\"value\"])\n",
    "        })\n",
    "    elif n[\"type\"] == \"pressure\":\n",
    "        output_json[\"boundary_conditions\"][\"pressure_boundary\"].append({\n",
    "            \"id\": n[\"id\"],\n",
    "            \"value\": list(n[\"value\"])\n",
    "        })\n",
    "\n",
    "\n",
    "if dirichlet.size > 0:\n",
    "    output_json[\"boundary_conditions\"][\"dirichlet_boundary\"] = [os.path.join(out_folder,\"dirichlet.txt\")]\n",
    "    \n",
    "    np.savetxt(os.path.join(out_folder,\"dirichlet.txt\"), dirichlet)\n",
    "    \n",
    "output_json[\"boundary_conditions\"][\"rhs\"] = [0,0,0]\n",
    "\n",
    "with open(os.path.join(out_folder, \"sim.json\"), \"w\") as f:\n",
    "    f.write(json.dumps(output_json, indent=\"  \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(T, c):\n",
    "    f = np.ndarray([T.shape[0]*4, 3], dtype=T.dtype)\n",
    "    outc = np.ndarray([T.shape[0]*4], dtype=c.dtype)\n",
    "    \n",
    "    for i in range(T.shape[0]):\n",
    "        f[i*4+0] = np.array([T[i][1], T[i][0], T[i][2]])\n",
    "        f[i*4+1] = np.array([T[i][0], T[i][1], T[i][3]])\n",
    "        f[i*4+2] = np.array([T[i][1], T[i][2], T[i][3]])\n",
    "        f[i*4+3] = np.array([T[i][2], T[i][0], T[i][3]])\n",
    "        \n",
    "        outc[i*4:i*4+4] = c[i]\n",
    "        \n",
    "    return f, outc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, c = convert(T, mids)\n",
    "mp.plot(V, f, c, shading={\"point_size\": 1, \"wireframe\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? mio.Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.find(\"Globals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
